# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1clIIhnzKBivBl2OiVpieP5pKcniPvEhe

#Import Data
"""

import gdown
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
import pandas as pd
import warnings
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import warnings
from tqdm import tqdm

"""#Load Dataset"""

# Ganti dengan ID asli dari file kamu
movie_id = '1Ssbz89-lBhXe8cOLeVLI7Rmp3noZf-Zv'
dataset = '1FwTwHlFEZbzP8wvBPl5iRM7x3-0BsJlP'

url_movie_id = f'https://drive.google.com/uc?id={movie_id}'
url_dataset = f'https://drive.google.com/uc?id={dataset}'

gdown.download(url_movie_id, 'Movie_Id_Titles.csv', quiet=False)
gdown.download(url_dataset, 'Dataset.csv', quiet=False)

# Load data
movie_id = pd.read_csv('Movie_Id_Titles.csv')
dataset = pd.read_csv('Dataset.csv')

"""#Data Understanding"""

movie_id.head()

dataset.head()

dataset.info()
movie_id.info()

"""#Data Preparation"""

merged_df = dataset.merge(movie_id, on='item_id')
merged_df.head()

merged_df.describe()

print(merged_df.shape)
print(merged_df.info())
print(merged_df.isnull().sum())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,5))
sns.countplot(x='rating', data=merged_df)
plt.title("Distribusi Rating")
plt.xlabel("Rating")
plt.ylabel("Jumlah")
plt.show()

top_rated_count = merged_df['title'].value_counts().head(10)

plt.figure(figsize=(10,6))
sns.barplot(x=top_rated_count.values, y=top_rated_count.index)
plt.title("10 Film yang Paling Banyak Dinilai")
plt.xlabel("Jumlah Rating")
plt.ylabel("Judul Film")
plt.show()

warnings.filterwarnings("ignore", category=RuntimeWarning)

# 1. Split data
train_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=42)

"""#Modeling"""

# Filter user & movie aktif
min_ratings_user = 10
min_ratings_movie = 10

active_users = train_df['user_id'].value_counts()
active_users = active_users[active_users >= min_ratings_user].index
train_df = train_df[train_df['user_id'].isin(active_users)]

popular_movies = train_df['title'].value_counts()
popular_movies = popular_movies[popular_movies >= min_ratings_movie].index
train_df = train_df[train_df['title'].isin(popular_movies)]

#Buat user-movie matrix
user_movie_matrix = train_df.pivot_table(index='user_id', columns='title', values='rating')

#Fungsi rekomendasi
def recommend_movies_for_user(user_id, user_movie_matrix, train_df, n_recommendations=10):
    if user_id not in user_movie_matrix.index:
        return pd.DataFrame()  # Cold-start user

    user_ratings = user_movie_matrix.loc[user_id]
    similar_scores = pd.Series(dtype='float64')

    for movie, rating in user_ratings.dropna().items():
        if user_movie_matrix[movie].count() < 2 or user_movie_matrix[movie].std() == 0:
            continue

        sim_movies = user_movie_matrix.corrwith(user_movie_matrix[movie])
        sim_movies = sim_movies.dropna()
        sim_movies = sim_movies * (rating - user_ratings.mean())  # normalisasi

        similar_scores = similar_scores.add(sim_movies, fill_value=0)

    recommendations = pd.DataFrame(similar_scores, columns=["score"])

    # Gabungkan dengan rating count
    rating_counts = train_df.groupby("title")["rating"].count()
    recommendations["rating_count"] = recommendations.index.map(rating_counts)

    # Buang film yang sudah ditonton user
    watched_movies = train_df[train_df['user_id'] == user_id]['title'].tolist()
    recommendations = recommendations[~recommendations.index.isin(watched_movies)]

    # Filter minimum rating_count
    recommendations = recommendations[recommendations["rating_count"] >= 2]

    # Skor akhir berbobot
    recommendations["final_score"] = recommendations["score"] * np.log1p(recommendations["rating_count"])

    # Urutkan berdasarkan final_score
    recommendations = recommendations.sort_values("final_score", ascending=False)

    return recommendations.head(n_recommendations)

"""#evaluation"""

# Evaluasi
def evaluate_recommender(test_df, train_df, user_movie_matrix, k=10, min_rating=4.0):
    precisions, recalls, f1s = [], [], []
    user_ids = test_df['user_id'].unique()

    for user_id in tqdm(user_ids, desc="Evaluating"):
        actual = test_df[(test_df['user_id'] == user_id) & (test_df['rating'] >= min_rating)]['title'].tolist()
        if not actual:
            continue

        recommended_df = recommend_movies_for_user(user_id, user_movie_matrix, train_df, n_recommendations=k)
        if recommended_df.empty:
            continue

        recommended_titles = recommended_df.index.tolist()

        tp = len(set(actual) & set(recommended_titles))
        precision = tp / k if k > 0 else 0
        recall = tp / len(actual) if len(actual) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        precisions.append(precision)
        recalls.append(recall)
        f1s.append(f1)

    avg_precision = sum(precisions) / len(precisions) if precisions else 0
    avg_recall = sum(recalls) / len(recalls) if recalls else 0
    avg_f1 = sum(f1s) / len(f1s) if f1s else 0

    print(f"\nHasil Evaluasi Sistem Rekomendasi:")
    print(f"Precision@{k}: {avg_precision:.4f}")
    print(f"Recall@{k}   : {avg_recall:.4f}")
    print(f"F1-Score@{k} : {avg_f1:.4f}")

    return avg_precision, avg_recall, avg_f1

# Sampling subset user dari test set
sampled_users = np.random.choice(test_df['user_id'].unique(), size=100, replace=False)
sampled_test_df = test_df[test_df['user_id'].isin(sampled_users)]

# Jalankan evaluasi
evaluate_recommender(sampled_test_df, train_df, user_movie_matrix, k=20, min_rating=3.5)